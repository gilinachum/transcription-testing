{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "222ce67c",
   "metadata": {},
   "source": [
    "# Deploying the Endpoint\n",
    "In this notebook we will deploy an endpoint with the model whisper-large-v2. We will write our inference code because we will use Whisper's API rather than the Hugging Face API. This is because the Whisper API allows for transcriptions longer tahn 30 seconds out of the box. The API can be found here: https://github.com/openai/whisper#python-usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdc6b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir model\n",
    "!mkdir model/code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3109396",
   "metadata": {},
   "source": [
    "We write out custome inference code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fb07f9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model/code/inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model/code/inference.py\n",
    "import whisper\n",
    "import boto3\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    model = whisper.load_model(\"large-v2\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def transcribe_from_s3(model, s3_file, language=None):\n",
    "    s3 = boto3.client('s3')\n",
    "    o = urlparse(s3_file, allow_fragments=False)\n",
    "    bucket = o.netloc\n",
    "    key = o.path.lstrip('/')\n",
    "    \n",
    "    s3.download_file(bucket, key, 'tmp.wav')\n",
    "    result = model.transcribe('tmp.wav', language=language)\n",
    "    \n",
    "    return result[\"language\"], result[\"text\"]\n",
    "\n",
    "\n",
    "def predict_fn(data, model):\n",
    "    s3_file = data.pop(\"s3_file\")\n",
    "    language = data.pop(\"language\", None)\n",
    "\n",
    "    detected_language, transcription = transcribe_from_s3(model, s3_file, language)\n",
    "    \n",
    "    return {\"detected_language\": detected_language, \"transcription\": transcription}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919d2764",
   "metadata": {},
   "source": [
    "And into the `requirements.txt` we put the libraries we will need to run the inference code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b6aaa2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model/code/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile model/code/requirements.txt\n",
    "transformers==4.25.1\n",
    "git+https://github.com/openai/whisper.git\n",
    "boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bcf385",
   "metadata": {},
   "source": [
    "## Uploading the model to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "12a317ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/transcription-testing/model\n"
     ]
    }
   ],
   "source": [
    "%cd model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "93e02e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ec7804a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code/\n",
      "code/.ipynb_checkpoints/\n",
      "code/.ipynb_checkpoints/inference-checkpoint.py\n",
      "code/requirements.txt\n",
      "code/inference.py\n"
     ]
    }
   ],
   "source": [
    "!tar zcvf model.tar.gz *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b1860be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::905847418383:role/service-role/AmazonSageMaker-ExecutionRole-20210804T091905\n",
      "sagemaker bucket: sagemaker-us-east-1-905847418383\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0ee3ff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_location = f\"s3://{sagemaker_session_bucket}/whisper/model/model.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "263f60d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./model.tar.gz to s3://sagemaker-us-east-1-905847418383/whisper/model/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp model.tar.gz $s3_location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05c1e5f",
   "metadata": {},
   "source": [
    "## Deplying the model to en endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6557fc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "endpoint_name = name_from_base(\"whisper-large-custom\")\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   model_data=s3_location,       # path to your model and script\n",
    "   role=role,                    # iam role with permissions to create an Endpoint\n",
    "   transformers_version=\"4.17\",  # transformers version used\n",
    "   pytorch_version=\"1.10\",        # pytorch version used\n",
    "   py_version='py38',            # python version used\n",
    ")\n",
    "\n",
    "# deploy the endpoint endpoint\n",
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g4dn.xlarge\",\n",
    "    endpoint_name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17839835",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"s3_file\": \"s3://sagemaker-us-east-1-905847418383/whisper/data/test/he/test-he-000.wav\",\n",
    "    \"language\": \"he\"\n",
    "}\n",
    "\n",
    "res = predictor.predict(data=data)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378d94db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
